<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>GHOST Benchmark</title>

  <!-- Fonts & Icons -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Favicon -->
  <link rel="icon" href="./static/images/favicon.svg">

  <!-- Bulma CSS (lightweight) -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- MathJax for equations -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    body { font-family: 'Noto Sans', 'Google Sans', system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }
    img { max-width: 100%; height: auto; }
    .publication-title { font-family: 'Castoro', serif; }
    .leaderboard-label { display:inline-block; padding:4px 10px; border-radius:12px; font-size: 0.85rem; margin-right:8px; }
    table.leaderboard td, table.leaderboard th { padding: 8px 10px; }
    table.leaderboard thead th { background: #f5f5f5; }
    table.leaderboard { width:100%; }
    .section-spacer { margin-top: 1.5rem; }
    .hero-logo { width:1.6em; vertical-align: middle; margin-right: .3rem; }
    .pill { display:inline-block; padding:.2rem .6rem; border-radius:999px; background:#f1f1f1; font-size:.85rem; }
    .muted { color:#6b7280; }
    .center { text-align:center; }
    .content ul { margin-left:1.2rem; }
  </style>
</head>

<body>

<!-- Header / Hero -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img class="hero-logo" src="static/images/ghost/ghost_logo.svg" alt="GHOST Logo"/>GHOST
          </h1>
          <h2 class="subtitle is-4">Getting to the Bottom of Hallucinations with a Multi-round Consistency Benchmark</h2>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://vibashan.github.io/" target="_blank" rel="noopener">Vibashan VS</a><sup>1,2</sup>,</span>
            <span class="author-block"><a href="http://nadinechang.com/" target="_blank" rel="noopener">Nadine Chang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=16Kb660AAAAJ&hl=de" target="_blank" rel="noopener">Jenny Schmalfuss</a><sup>2,3</sup>,</span>
            <span class="author-block"><a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/" target="_blank" rel="noopener">Vishal M. Patel</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://chrisding.github.io/" target="_blank" rel="noopener">Zhiding Yu</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://alvarezlopezjosem.github.io/" target="_blank" rel="noopener">Jose M. Alvarez</a><sup>2</sup></span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block">Johns Hopkins University<sup>1</sup>,</span>
            <span class="author-block">NVIDIA<sup>2</sup>,</span>
            <span class="author-block">University of Stuttgart<sup>3</sup></span>
          </div>

          <div class="section-spacer">
            <div class="buttons is-centered">
              <a class="button is-dark is-rounded" href="#" target="_blank" rel="noopener">
                <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (arXiv 2025)</span>
              </a>
              <a class="button is-dark is-rounded" href="#" target="_blank" rel="noopener">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code </span>
              </a>
              <a class="button is-dark is-rounded" href="#" target="_blank" rel="noopener">
                <span class="icon"><i class="ai ai-dataverse"></i></span><span>Dataset </span>
              </a>
              <a class="button is-dark is-rounded" href="#" target="_blank" rel="noopener">
                <span class="icon"><i class="fas fa-sliders-h"></i></span><span>Slides</span>
              </a>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- Introduction -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <img src="./static/images/ghost/intro v9-1.png" alt="GHOST Benchmark Overview" />
        <div class="content has-text-justified">
          <ul>
            <li>
              <img src="static/images/ghost/ghost_logo.svg" class="hero-logo" alt="GHOST"> <strong>GHOST</strong> is an
              <strong>object-centric hallucination benchmark</strong> for evaluating Multimodal Large Language Models (MLLMs)
              on fine-grained object-level understanding.
            </li>
            <li>
              We evaluate individual objects via <em>compositional triplets</em>: (<em>object type</em>, <em>attribute</em>, <em>relation</em>).
            </li>
            <li>
              We introduce <strong>Consistency Checks (CC)</strong> across positive (true) and hard negative (false) statements for the
              same object and define the GHOST Consistency Score (GCS) to quantify hallucination tendencies.
            </li>
            <li>
              GHOST contains 765 images and 3,174compositional triplets, resulting in <strong>38,088</strong> questions, and
              we evaluate <strong>20</strong> state-of-the-art MLLMs.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Leaderboard (concise, single table) -->
<section class="section" id="leaderboard">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">GHOST Leaderboard</h2>
        <p class="content has-text-justified">
          We report <strong>GCS</strong> (higher is better) for <em>Overall</em>, and by component: <em>Object</em>, <em>Attribute</em>,
          and <em>Relation</em>. Values below are taken from the paper.
        </p>
        <div class="model-labels-container center section-spacer">
          <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.15);">Open-Source</span>
          <span class="leaderboard-label" style="background-color: rgba(230, 230, 250, 1);">Proprietary</span>
        </div>

        <div class="table-container">
          <table class="table leaderboard is-striped is-hoverable is-fullwidth">
            <thead>
              <tr>
                <th>Model</th>
                <th>Size</th>
                <th>Overall</th>
                <th>Object</th>
                <th>Attribute</th>
                <th>Relation</th>
              </tr>
            </thead>
            <tbody>
              <!-- Tiny MLLMs -->
              <tr style="background-color: rgba(255, 182, 193, 0.2);"><td colspan="6" class="has-text-centered"><strong>Tiny MLLMs (&lt;4B)</strong></td></tr>
              <tr><td class="has-text-left">LLaVA-OneVision</td><td>0.5B</td><td>45.6</td><td>68.8</td><td>57.5</td><td>10.5</td></tr>
              <tr><td class="has-text-left">MiniCPM-V</td><td>2B</td><td>44.5</td><td>63.9</td><td>49.8</td><td>19.8</td></tr>
              <tr><td class="has-text-left">PaliGemma</td><td>3B</td><td>46.6</td><td>75.7</td><td>53.3</td><td>10.6</td></tr>
              <tr><td class="has-text-left">VILA-1.5</td><td>3B</td><td>53.2</td><td>78.7</td><td>62.2</td><td>18.7</td></tr>

              <!-- Small - Medium MLLMs -->
              <tr style="background-color: rgba(255, 255, 224, 0.5);"><td colspan="6" class="has-text-centered"><strong>Small–Medium MLLMs (4B–13B)</strong></td></tr>
              <tr><td class="has-text-left">Phi-3.5-V</td><td>4B</td><td>55.8</td><td>78.3</td><td>52.2</td><td>36.9</td></tr>
              <tr><td class="has-text-left">Chameleon</td><td>7B</td><td>41.4</td><td>44.7</td><td>40.8</td><td>38.8</td></tr>
              <tr><td class="has-text-left">Mantis-LLaMA3</td><td>8B</td><td>54.0</td><td>77.8</td><td>55.3</td><td>29.0</td></tr>
              <tr><td class="has-text-left">VILA-1.5</td><td>8B</td><td>60.3</td><td>84.1</td><td>63.6</td><td>33.2</td></tr>
              <tr><td class="has-text-left">Eagle-X4-Plus</td><td>8B</td><td>64.1</td><td>86.2</td><td>63.1</td><td>43.1</td></tr>
              <tr><td class="has-text-left">LLaVA-OneVision</td><td>8B</td><td>64.4</td><td><strong>86.5</strong></td><td>67.5</td><td>39.1</td></tr>
              <tr><td class="has-text-left">Idefics</td><td>9B</td><td>39.2</td><td>50.5</td><td>47.5</td><td>19.5</td></tr>
              <tr><td class="has-text-left">LLaVA-1.5</td><td>13B</td><td>58.2</td><td>80.2</td><td>56.4</td><td>37.9</td></tr>
              <tr><td class="has-text-left">VILA-1.5</td><td>13B</td><td>64.5</td><td>84.3</td><td><strong>68.8</strong></td><td>40.2</td></tr>

              <!-- Large MLLMs -->
              <tr style="background-color: rgba(144, 238, 144, 0.35);"><td colspan="6" class="has-text-centered"><strong>Large MLLMs (&gt;13B)</strong></td></tr>
              <tr><td class="has-text-left">MiniCPM-LLaMA3</td><td>18B</td><td>63.9</td><td>79.9</td><td>65.4</td><td>46.4</td></tr>
              <tr><td class="has-text-left">CogVLM2</td><td>20B</td><td>47.1</td><td>74.0</td><td>51.2</td><td>16.1</td></tr>
              <tr><td class="has-text-left">InternVL-Chat</td><td>26B</td><td>61.1</td><td>84.2</td><td>61.8</td><td>37.5</td></tr>
              <tr><td class="has-text-left">VILA-1.5</td><td>40B</td><td>66.0</td><td>85.9</td><td>67.7</td><td>44.4</td></tr>
              <tr><td class="has-text-left">LLaVA-OneVision</td><td>72B</td><td>68.4</td><td>84.0</td><td>68.2</td><td><strong>53.1</strong></td></tr>

              <!-- Proprietary -->
              <tr style="background-color: rgba(230, 230, 250, 0.6);"><td colspan="6" class="has-text-centered"><strong>Proprietary MLLMs</strong></td></tr>
              <tr><td class="has-text-left">Gemini 1.5 Pro</td><td>–</td><td>64.1</td><td>79.3</td><td>67.1</td><td>46.0</td></tr>
              <tr><td class="has-text-left">GPT-4o</td><td>–</td><td><strong>69.0</strong></td><td>82.2</td><td><strong>68.9</strong></td><td><strong>56.0</strong></td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- GCS Definition -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">GHOST Consistency Score (GCS)</h2>
        <div class="content has-text-justified">
          <img src="./static/images/ghost/motivation_plot-1.png" alt="Consistency vs. Accuracy" />
          <p>
            To evaluate an MLLM and reveal hallucinations via consistency checks, we propose the <strong>GHOST Consistency Score (GCS)</strong>.
            Unlike image-level metrics that treat questions independently, GCS penalizes hallucinations according to their frequency using
            exponentially decaying weights.
          </p>
          <p class="center">
            $$ \text{GCS} = 1 - \left( \sum_{i=1}^{N_{\text{hallu}}} \frac{1}{2^{i-1}} \right) \Big/ \left( \sum_{i=1}^{N_{\text{total}}} \frac{1}{2^{i-1}} \right) $$
          </p>
          <p>
            Here, \(N_{\text{hallu}}\) is the number of hallucinations (\(\mathrm{FP}+\mathrm{FN}\)), and \(N_{\text{total}}\) is the total number of
            questions in the category (object, attribute, relation). The weights \(w_i = 2^{-(i-1)}\) emphasize that even a single hallucination is
            highly informative of misunderstanding. The overall score averages categories:
          </p>
          <p class="center">
            $$ \text{Overall GCS} = \tfrac{1}{3}\, (\, \text{GCS}_{\text{obj}} + \text{GCS}_{\text{attr}} + \text{GCS}_{\text{rel}}\,) $$
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Effects: Vision Encoder & LLM Size -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Vision Encoder and LLM Size Effects</h2>
        <div class="content has-text-justified">
          <div class="columns is-variable is-6 is-vcentered">
            <!-- Vision Encoder card -->
            <div class="column">
              <figure class="has-text-centered">
                <img src="./static/images/ghost/vision_effect_plot-1.png" alt="Vision encoder effect" height="250" width="auto">
                <figcaption class="muted" style="margin-top:.5rem">Vision encoder effect</figcaption>
              </figure>
              <ul style="margin-top:.5rem">
                <li><strong>Stronger encoders reduce hallucinations</strong> across all categories, with the largest gains on <em>relations</em>.</li>
                <li><strong>Quality beats quantity:</strong> MoE/SigLIP-style encoders (e.g., Eagle-X4) outperform models trained on far more data (e.g., CogVLM2).</li>
                <li><strong>Practicality:</strong> Better encoders improve reliability for resource-constrained and on-device deployments.</li>
              </ul>
            </div>
            <!-- LLM Size card -->
            <div class="column">
              <figure class="has-text-centered">
                <img src="./static/images/ghost/llm_effect_plot-1.png" alt="LLM size effect" height="250" width="auto">
                <figcaption class="muted" style="margin-top:.5rem">LLM size effect</figcaption>
              </figure>
              <ul style="margin-top:.5rem">
                <li><strong>Scaling helps:</strong> Larger LLMs consistently achieve higher GCS, especially on <em>relations</em>.</li>
                <li><strong>But:</strong> When hard negatives are added, <em>all sizes</em> show residual inconsistencies—highlighting limits of pure scaling.</li>
                <li><strong>Guidance:</strong> Prefer a balanced recipe—adequate LLM capacity paired with a strong vision encoder.</li>
              </ul>
            </div>
          </div>

          <p style="margin-top:1rem">
            <strong>Takeaways.</strong> (1) <em>Encoder quality is a first-order lever</em> for reducing object-level hallucinations and boosting relation understanding; invest in strong visual encoders (e.g., SigLIP, MoE Vision). (2) <em>LLM scaling improves consistency</em>, but consistency checks with hard negatives still surface weaknesses—so combine capacity with encoder quality and evaluate with object-centric consistency.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<pre><code>@misc{vs2025ghost,
  title={{GHOST}: Getting to the Bottom of Hallucinations with a Multi-round Consistency Benchmark},
  author={VS, Vibashan and Chang, Nadine and Schmalfuss, Jenny and Patel, Vishal M. and Yu, Zhiding and Alvarez, Jose M.},
  year={2025},
  eprint={},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}</code></pre>
  </div>
</section>

<!-- Footer / Acknowledgement -->
<section class="section">
  <div class="container is-max-desktop content center">
    <p class="muted">Website template adapted from <a href="https://nerfies.github.io/" target="_blank" rel="noopener">Nerfies</a>. Images © the authors.</p>
  </div>
</section>

</body>
</html>
